from typing import Dict, Any, List

from bs4 import BeautifulSoup

from crawler.base import AsyncCrawlerBase
from models.ticket import TicketInfo
from utils import normalize_date_string
from utils.config import settings
from html import unescape
from datetime import datetime
import re


class SejongPac(AsyncCrawlerBase):
    def __init__(self, date_range):
        super().__init__(date_range)
        self.cfg = settings.CRAWLERS['sejong_pac']
        self.list_url = self.cfg['list_endpoint']
        self.BASE_URL = self.cfg['base_url']

    def parse_td_with_paragraphs_or_list(self, td_tag):
        """<p> ë˜ëŠ” <li> ê¸°ì¤€ìœ¼ë¡œ ì¤„ë°”ê¿ˆ ì •ë¦¬. ë¹ˆ ì¤„ ì œê±°"""
        lines = []

        # <p> íƒœê·¸
        for p in td_tag.find_all("p"):
            text = p.get_text(strip=True)
            if text:
                lines.append(text)

        # <li> íƒœê·¸ (í•­ìƒ ì¶”ê°€. <p>ì™€ ë³‘ì¡´ ê°€ëŠ¥)
        for li in td_tag.find_all("li"):
            text = li.get_text(strip=True)
            if text:
                lines.append(text)

        # <br> ì²˜ë¦¬ (ìœ„ ë‘˜ ëª¨ë‘ ì—†ì„ ë•Œë§Œ)
        if not lines:
            brs = td_tag.find_all("br")
            if brs:
                raw = td_tag.get_text(separator="\n")
                for part in raw.split("\n"):
                    part = part.strip()
                    if part:
                        lines.append(part)

        # ì•„ë¬´ ê²ƒë„ ì—†ì„ ê²½ìš° fallback
        if not lines:
            text = td_tag.get_text(strip=True)
            if text:
                lines.append(text)

        return lines

    async def _fetch_list(self, session) -> List[Dict]:
        items = []
        for page in self.cfg['pages']:
            payload = self.cfg["params"]
            payload['pageIndex'] = str(page)

            async with session.get(self.list_url, params=payload) as response:
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                rows = soup.select("div.tbl_list > table > tbody > tr")
                for row in rows:
                    cols = row.findcols = row.find_all("td")
                    if len(cols) < 6:
                        continue

                    title_tag = cols[1].find("a")
                    title = unescape(title_tag.get_text(strip=True))
                    link = self.BASE_URL + title_tag["href"]

                    open_date = cols[3].get_text(strip=True)
                    norm = normalize_date_string(open_date)
                    dt = datetime.strptime(norm, "%Y-%m-%d %H:%M")
                    if not (self.start <= dt <= self.end):
                        continue

                    items.append({
                        "title": title,
                        "link": link,
                        "open_date": dt,
                    })
        return items

    async def _fetch_detail(self, session, item: Dict[str, Any]) -> List[TicketInfo]:
        # print("ì„¸ì¢…ë¬¸í™”íšŒê´€ ìƒì„¸ì •ë³´ ìˆ˜ì§‘:", item["title"], item["link"], item["open_date"])
        tickets: List[TicketInfo] = []

        content = {}
        detail_html = await (await session.get(item["link"])).text()
        soup = BeautifulSoup(detail_html, "html.parser")
        category = venue = round_info = cast = None;
        open_type = "ì¼ë°˜ì˜ˆë§¤"
        title = item["title"]
        solo_sale = False

        # (1) content ì±„ìš°ê¸°
        table = soup.find("table")
        if table:
            for row in table.select("tr"):
                th = row.find("th")
                td = row.find("td")
                if th and td:
                    key = th.get_text(strip=True)
                    value = "\n".join(self.parse_td_with_paragraphs_or_list(td))
                    content[key] = value

        # (5) í‹°ì¼“ì˜¤í”ˆì¼
        open_section = soup.find('th', string='í‹°ì¼“ì˜¤í”ˆì¼')
        open_entries = []
        if open_section:
            open_td = open_section.find_next_sibling("td")
            open_lines = self.parse_td_with_paragraphs_or_list(open_td)
            for line in open_lines:
                # ë¨¼ì € ë‚ ì§œ ë¬¸ìì—´ì„ í‘œì¤€ í¬ë§·(YYYYë…„ MMì›” DDì¼ HH:MM)ìœ¼ë¡œ ì •ê·œí™”
                nds = normalize_date_string(line)
                m = re.search(
                    r'(?:^|:)\s*(\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼\s*(?:ì˜¤ì „|ì˜¤í›„)?\s*\d{1,2}(?:ì‹œ|:\d{2})(?:\s*\d{1,2}ë¶„)?)',
                    nds
                )

                if not m:
                    continue

                date_str = m.group(1)

                if "ì˜¤ì „" in date_str or "ì˜¤í›„" in date_str:
                    # ğŸ§  ì˜¤ì „/ì˜¤í›„ ìˆëŠ” ê²½ìš°ëŠ” ì§ì ‘ íŒŒì‹±
                    d = re.search(
                        r'(?P<year>\d{4})ë…„\s*(?P<month>\d{1,2})ì›”\s*(?P<day>\d{1,2})ì¼\s*'
                        r'(?P<ampm>ì˜¤ì „|ì˜¤í›„)?\s*(?P<hour>\d{1,2})(ì‹œ|:)(\s*(?P<minute>\d{1,2})ë¶„?)?',
                        date_str
                    )
                    if d:
                        year = int(d.group("year"))
                        month = int(d.group("month"))
                        day = int(d.group("day"))
                        hour = int(d.group("hour"))
                        minute = int(d.group("minute") or 0)
                        ampm = d.group("ampm")

                        if ampm == "ì˜¤í›„" and hour < 12:
                            hour += 12
                        if ampm == "ì˜¤ì „" and hour == 12:
                            hour = 0

                        open_time = datetime(year, month, day, hour, minute)
                    else:
                        continue  # ì˜ˆì™¸ ì²˜ë¦¬: íŒŒì‹± ì‹¤íŒ¨ ì‹œ skip
                else:
                    # âœ… ì˜¤ì „/ì˜¤í›„ ì—†ëŠ” ê²½ìš°ëŠ” ê·¸ëŒ€ë¡œ íŒŒì‹±
                    open_time = datetime.strptime(date_str, "%Yë…„ %mì›” %dì¼ %H:%M")

                # ë‚ ì§œ ë’¤ì— ë¶™ì€ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¼ë‚´ê³ , ì—†ìœ¼ë©´ "ì¼ë°˜ì˜ˆë§¤"ë¡œ
                open_target = nds[m.end():].strip()

                if not open_target:
                    open_target = nds[:m.start()].strip().rstrip(":").replace("-", "")

                if not open_target:
                    open_target = "ì¼ë°˜ì˜ˆë§¤"

                # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ëª¨ì•„ë‘ê¸°
                open_entries.append({
                    "time": open_time,
                    "target": open_target
                })

        # (2) í‹°ì¼“ì˜¤í”ˆíšŒì°¨ ì¶”ì¶œ
        round_section = soup.find('th', string='í‹°ì¼“ì˜¤í”ˆíšŒì°¨')
        if round_section:
            round_info = round_section.find_next_sibling("td").get_text(strip=True)

        # (3) ê³µì—°ì •ë³´ í•­ëª© ìƒì„¸ íŒŒì‹±
        info_section = soup.find('th', string='ê³µì—°ì •ë³´')
        if info_section:
            info_td = info_section.find_next_sibling("td")
            info_lines = self.parse_td_with_paragraphs_or_list(info_td)

            for line in info_lines:
                if "ê³µì—°ëª…" in line:
                    title = line.split("ê³µì—°ëª…")[-1].strip(": ï¼š Â·").strip()
                    if "ì—°ê·¹" in title:
                        category = "ì—°ê·¹"
                    elif "ë®¤ì§€ì»¬" in title:
                        category = "ë®¤ì§€ì»¬"
                    elif "ì½˜ì„œíŠ¸" in title:
                        category = "ì½˜ì„œíŠ¸"
                    elif "í´ë˜ì‹" in title:
                        category = "í´ë˜ì‹"
                    else:
                        category = "ê¸°íƒ€"
                elif "ê³µì—°ì¥ì†Œ" in line:
                    venue = line.split("ê³µì—°ì¥ì†Œ")[-1].strip(": ï¼š Â·").strip()
                elif "ì„ ì˜ˆë§¤" in line:
                    open_type = "ì„ ì˜ˆë§¤"
                if "ì„¸ì¢…ë¬¸í™”í‹°ì¼“ì—ì„œë§Œ" in line:
                    solo_sale = True

        # (4) ì¶œì—°ì§„
        intro_section = soup.find('th', string='ê³µì—°ì†Œê°œ')
        if intro_section:
            intro_td = intro_section.find_next_sibling("td")
            cast = self.extract_cast_from_td(intro_td)

        # print(f"ì„¸ì¢…ë¬¸í™”íšŒê´€: {title} {item['open_date']} {category} {round_info} {cast} {solo_sale} {venue} {item['link']} {open_type} {content}")

        # (6) í‹°ì¼“ì •ë³´ ìƒì„±
        for open_item in open_entries:
            open_dt = open_item["time"]

            tickets.append(TicketInfo(
                title=title,  # ê³µì—° ì œëª©
                open_datetime=open_dt,  # ì˜¤í”ˆ ì¼ì‹œ
                round_info=round_info or "-",  # ì˜¤í”ˆ íšŒì°¨
                cast=", ".join(cast) if cast else "-",  # ì¶œì—°ì§„
                detail_url=item["link"],  # ìƒì„¸ ë§í¬
                category=category or "-",  # êµ¬ë¶„
                open_type=open_item["target"],  # ì˜¤í”ˆ íƒ€ì…
                venue=venue or "-",  # ê³µì—° ì¥ì†Œ
                providers={"ì„¸ì¢…ë¬¸í™”íšŒê´€"},  # ì˜ˆë§¤ì²˜
                solo_sale=solo_sale,  # ë‹¨ë… íŒë§¤
                content=content,  # ë‚´ìš©
                source="ì„¸ì¢…ë¬¸í™”íšŒê´€"  # ì˜ˆë§¤ì²˜(ì›ë³¸)
            ))

        return tickets


    def extract_cast_from_td(self, td_tag):
        # 1) <p> íƒœê·¸ë³„ë¡œ í…ìŠ¤íŠ¸ë¥¼ í•œ ì¤„ì”© ë½‘ì•„ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ
        lines = self.parse_td_with_paragraphs_or_list(td_tag)

        cast = []
        for idx, line in enumerate(lines):
            # 2) 'ì¶œì—°ì§„', 'ìºìŠ¤íŒ…', 'cast' í—¤ë” íƒì§€ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            if re.search(r'\b(ì¶œì—°ì§„|ìºìŠ¤íŒ…|cast|ìºë¦­í„°)\b', line, re.I):
                # 3a) ê°™ì€ ì¤„ì— â€œ:â€ ê°€ ìˆìœ¼ë©´, : ë’¤ë§Œ split
                if ":" in line:
                    after = line.split(":", 1)[1]
                    cast.append(after);
                else:
                    # 3b) ì•„ë‹ˆë©´ ë‹¤ìŒ ì¤„ë¶€í„°, ë¹ˆ ì¤„ ë˜ëŠ” ìƒˆ ì„¹ì…˜(ëŒ€ê´„í˜¸ ë“±) ë‚˜ì˜¤ê¸° ì „ê¹Œì§€
                    for nxt in lines[idx + 1:]:
                        if not nxt:
                            break
                        # ìƒˆ ì„¹ì…˜ìœ¼ë¡œ ë³´ì´ëŠ” [..] ë§Œë‚  ê²½ìš° ì¤‘ë‹¨
                        if re.match(r'^\[.+\]$', nxt) or re.search(r'\b(ê³µì—° ì •ë³´|creative team|ì°½ì‘ì§„)\b', line, re.I):
                            break
                        if re.search(r'\b(ìºë¦­í„°)\b', line, re.I) and not "/" in nxt:
                            # ìºë¦­í„° ì •ë³´ì¸ ê²½ìš°, ìºë¦­í„° ì´ë¦„ë§Œ ì¶”ì¶œ
                            continue
                        else:
                            cast.append(nxt)

                break
        return cast
